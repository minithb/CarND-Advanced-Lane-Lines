{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "i = 0\n",
    "draw_img = None\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    draw_img = np.copy(img)\n",
    "    \n",
    "    # Convert to GrayScale image\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(draw_img, (9,6), corners, ret)\n",
    "# Use cv2.calibrateCamera to get distortion coefficients and calibration matrix        \n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (draw_img.shape[0], draw_img.shape[1]), None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Undistort Chessboard Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initializing counter to save image as Undistort1.jpg, Undistort2.jpg etc...\n",
    "i = 0\n",
    "# Create list of images to undistort\n",
    "images = ['camera_cal/calibration1.jpg','camera_cal/calibration2.jpg','camera_cal/calibration3.jpg',\n",
    "          'camera_cal/calibration4.jpg','camera_cal/calibration5.jpg']\n",
    "# Looping through above images to undistort and save\n",
    "for fname in images:\n",
    "    # Read image\n",
    "    img = cv2.imread(fname)\n",
    "    draw_img = np.copy(img)\n",
    "    # Increment counter\n",
    "    i += 1\n",
    "    # cv2.undistort()\n",
    "    dest = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # Define path to save the figure\n",
    "    path = 'output_images/Undistorted_Images/Undistort'+str(i)+'.jpg'\n",
    "    # Define figure\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    f.tight_layout()\n",
    "    # Add Original Image to figure\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=25)\n",
    "    # Add Undistorted image to figure\n",
    "    ax2.imshow(dest)\n",
    "    ax2.set_title('Undistorted Image', fontsize=25)\n",
    "    # Save figure\n",
    "    plt.savefig(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate tranformation matrix and calibration matix using Image & Object points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define source 'src' and destination 'dst' points\n",
    "# I have hardcoded this values for this project, can be generic using formula in writeup.md file\n",
    "src = np.float32([[585, 460], [203, 720], [1127, 720], [695, 460]])\n",
    "dst = np.float32([[320, 0], [320, 720], [960, 720], [960, 0]])\n",
    "# Compute tranform matrix M using cv2.getPerspectiveTransform()\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "# Compute inverse tranform matrix Minv using cv2.getPerspectiveTransform()\n",
    "Minv = cv2.getPerspectiveTransform(dst, src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find binary warped image using color conversion, gradient etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_warped_images(image, s_thresh=(100, 255), sx_thresh=(20, 100), caller = False):\n",
    "    #Use cv2.undistort() to undistort image\n",
    "    dest = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    img = np.copy(dest)\n",
    "    \n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    # Extracting 'L' channel from image 'hls'\n",
    "    l_channel = hls[:,:,1]\n",
    "    # Extracting 'S' channel from image 'hls'\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    # Define combined and final image \n",
    "    combined = np.zeros_like(s_binary)\n",
    "    final = np.zeros_like(s_binary)\n",
    "    # Combining image 'sxbinary' and 's_binary' using OR operator \n",
    "    combined[(sxbinary == 1) | (s_binary == 1)] = 1\n",
    "    \n",
    "    # Experiment done to make broken lane line continuous using hough transform\n",
    "    '''combined = combined.astype(np.uint8)\n",
    "    final = combined\n",
    "    #color_binary = np.dstack(( np.zeros_like(s_binary), sxbinary, s_binary))\n",
    "    \n",
    "    mask = np.zeros_like(combined)\n",
    "    ignore_mask_color = 255\n",
    "    \n",
    "    # This time we are defining a four sided polygon to mask\n",
    "    vertices = np.array([[(800, 450), (1150, 680), (150, 680), (500, 450)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    combined1 = cv2.bitwise_and(combined, mask)\n",
    "    \n",
    "    #vertices = np.array([[(580, 450), (770, 450), (1150, 680), (350, 680)]], dtype=np.int32)\n",
    "    #masked_edges = region_of_interest(combined, vertices)\n",
    "    line_image = hough_lines(combined1, 2, np.pi/180, 40, 60, 100)\n",
    "    line_image = line_image[:,:,0]\n",
    "    result = weighted_img(line_image, combined)\n",
    "    \n",
    "    combined = result // 255'''\n",
    "    \n",
    "    # Define mask image to mask left and right lane lines.\n",
    "    mask = np.zeros_like(combined)\n",
    "    ignore_mask_color = 1\n",
    "    \n",
    "    # This time we are defining a four sided polygon to mask left lane\n",
    "    vertices = np.array([[(580, 460), (620, 460), (350, 680), (150, 680)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    combined1 = cv2.bitwise_and(combined, mask)\n",
    "    \n",
    "    # This time we are defining a four sided polygon to mask right lane\n",
    "    vertices = np.array([[(710,460),(760, 460), (1200, 680), (1000,680)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    combined2 = cv2.bitwise_and(combined, mask)\n",
    "    \n",
    "    # Combining mask images 'combined1' and 'combined2' using OR operator\n",
    "    final[(combined1 == 1) | (combined2 == 1)] = 1\n",
    "    combined = final\n",
    "    \n",
    "    # Getting warped image using perspective transform\n",
    "    binary_warped, warped = get_perspective_transform(combined, image)\n",
    "    \n",
    "    # Return all images if call is from test images pipeline\n",
    "    # else return only 'binary_warped' and 'dest' images, if call is from pipeline for videos\n",
    "    if caller:\n",
    "        return binary_warped, warped, dest, combined\n",
    "    else:\n",
    "        return binary_warped, dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_perspective_transform(combined, image):\n",
    "    combined_size = combined.shape[::-1]\n",
    "    # use cv2.warpPerspective to get binary warped image 'binary_warped' using binary image 'combined'\n",
    "    binary_warped = cv2.warpPerspective(combined, M, combined_size, flags = cv2.INTER_LINEAR)\n",
    "    # use cv2.warpPerspective to get warped image 'binary_warped' using 3 channel image 'image'\n",
    "    warped = cv2.warpPerspective(image, M, combined_size, flags = cv2.INTER_LINEAR)\n",
    "    binary_warped = binary_warped.astype(np.uint8)\n",
    "    \n",
    "    # Return warped images\n",
    "    return binary_warped, warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## Find midpoint and peaks of left and right line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_values(binary_warped):\n",
    "    # Calculate histogram along x-axis\n",
    "    histogram = np.sum(binary_warped[int(binary_warped.shape[0]/2):,:], axis=0)\n",
    "    # Find midpoint\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    # Find left lane line base\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    # Find right lane line base    \n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # Return midpoint, left base and right base\n",
    "    return midpoint, leftx_base, rightx_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find polynimial fit of left lane and right lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_fits(binary_warped, caller = False):\n",
    "    \n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint, leftx_base, rightx_base = get_values(binary_warped)\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(out_img.shape[0]/nwindows)\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = int(out_img.shape[0]) - (window+1)*window_height\n",
    "        win_y_high = int(out_img.shape[0]) - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        #cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        #cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Assingn red color to index belonging to left lane line\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    # Assingn blue color to index belonging to right lane line    \n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    # Return left_fit, right_fit and image 'out_img' if call is from test images pipeline\n",
    "    # else return only left_fit, right_fit, if call is from pipeline for videos\n",
    "    if caller:\n",
    "        return left_fit, right_fit, out_img\n",
    "    else:\n",
    "        return left_fit, right_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Calculate Radius of Curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_radius_of_curvature(ploty, left_fit, right_fit):\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Calculate x co-ordinates belonging to left lane line\n",
    "    leftx = left_fit[0] * ploty**2 + left_fit[1] * ploty + left_fit[2]\n",
    "    # Calculate x co-ordinates belonging to right lane line    \n",
    "    rightx = right_fit[0] * ploty**2 + right_fit[1] * ploty + right_fit[2]\n",
    "    # Find max y co-ordinate, point at which we want to find radius of curvature \n",
    "    y_eval = np.max(ploty)\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[\n",
    "                     1])**2)**1.5) / np.absolute(2 * left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2 * right_fit_cr[0] * y_eval * ym_per_pix + right_fit_cr[\n",
    "                      1])**2)**1.5) / np.absolute(2 * right_fit_cr[0])\n",
    "    \n",
    "    # Return radius of curvature\n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Offset from center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_offset_from_center(binary_warped, left_fit, right_fit):\n",
    "    # Get y, y co-ordinate at which we want to find the position of vehicle\n",
    "    y = binary_warped.shape[0]\n",
    "    # Calculate x co-ordinate for left lane line corresponding to y \n",
    "    left_point = left_fit[0] * y**2 + left_fit[1] * y + left_fit[2]\n",
    "    # Calculate x co-ordinate for right lane line corresponding to y\n",
    "    right_point = right_fit[0] * y**2 + right_fit[1] * y + right_fit[2]\n",
    "    # # Define conversions in x from pixels space to meters\n",
    "    xm_per_pix = 3.7 / 700  # meteres per pixel in x dimension\n",
    "    # Get center point\n",
    "    road_midpoint = binary_warped.shape[1] / 2\n",
    "    # Get center point of car\n",
    "    car_midpoint = int((right_point + left_point) / 2)\n",
    "    # Calculate offset by taking difference\n",
    "    pixels_off_center = road_midpoint - car_midpoint\n",
    "    # Converting offset from pixel to meter using xm_per_pix\n",
    "    offset_from_center = xm_per_pix * pixels_off_center\n",
    "    # Return offset_from_center\n",
    "    return offset_from_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Unwarped image using Inverse Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_warped_back(dest, left_fitx, right_fitx, ploty):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(dest[:,:,0]).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 255))\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (dest.shape[1], dest.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    warped_back = cv2.addWeighted(dest, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    return warped_back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_final_result(result, avg_radius, offset_from_center):\n",
    "    \n",
    "    # Print radius of curvature on video\n",
    "    cv2.putText(result, 'Radius of Curvature = {}(m)'.format(avg_radius), (150, 200),\n",
    "                fontFace=16, fontScale=2, color=(255, 255, 0), thickness=2)\n",
    "    \n",
    "    # Check the position of vehicle, Left or Right\n",
    "    if offset_from_center < 0:\n",
    "        # Print distance from center on video\n",
    "        cv2.putText(result, 'Vehicle is {:.2f}m left of center'.format(abs(offset_from_center)), (150, 100),\n",
    "                        fontFace=16, fontScale=2, color=(255, 255, 0), thickness=2)\n",
    "    else:\n",
    "        # Print distance from center on video\n",
    "        cv2.putText(result, 'Vehicle is {:.2f}m right of center'.format(offset_from_center), (150, 100),\n",
    "                        fontFace=16, fontScale=2, color=(255, 255, 0), thickness=2)\n",
    "    # Return result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Pipeline to test on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define counter to save test images in respective folders\n",
    "i = 0\n",
    "raw_images = glob.glob('test_images/*.jpg')\n",
    "# Looping test images through pipeline\n",
    "for fname in raw_images:\n",
    "    # Read images\n",
    "    image = mpimg.imread(fname)\n",
    "    \n",
    "    #binary_warped, warped, dest, combined = get_better_warped(image, caller = True)\n",
    "    binary_warped, warped, dest, combined = get_warped_images(image, caller = True)    \n",
    "    \n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    left_fit, right_fit, out_img = get_fits(binary_warped, caller = True)\n",
    "    \n",
    "    # Get y co-ordinates using np.linspace\n",
    "    ploty = np.linspace(0, int(binary_warped.shape[0])-1, int(binary_warped.shape[0]))\n",
    "    # Calculate x co-ordinates belonging to left lane line\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    # Calculate x co-ordinates belonging to right lane line\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    # Get Radius of Curvature\n",
    "    left_curverad, right_curverad = get_radius_of_curvature(ploty, left_fit, right_fit)\n",
    "    \n",
    "    # Get Unwarped image 'warped_back'\n",
    "    warped_back = get_warped_back(dest, left_fitx, right_fitx, ploty)\n",
    "    \n",
    "    # Get position of vehicle w.r.t center\n",
    "    offset_from_center = get_offset_from_center(binary_warped, left_fit, right_fit)\n",
    "    \n",
    "    # Get final result having radius of curvature and offset\n",
    "    result = get_final_result(warped_back, int((left_curverad + right_curverad) / 2), offset_from_center)\n",
    "    \n",
    "    # Definig list of folders\n",
    "    folder = ['straight_lines1', 'straight_lines2', 'test1', 'test2', 'test3', 'test4', 'test5', 'test6','test7','test8']\n",
    "    \n",
    "    # Create figue to save undistorted image\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    f.tight_layout()\n",
    "    \n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=40)\n",
    "\n",
    "    ax2.imshow(dest)\n",
    "    ax2.set_title('Undistorted Image', fontsize=40)\n",
    "    path = 'output_images/'+folder[i]+'/Undistort.jpg'\n",
    "    plt.savefig(path)\n",
    "\n",
    "    # Create figure to save Warped image\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    f.tight_layout()\n",
    "    \n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=40)\n",
    "\n",
    "    ax2.imshow(warped)\n",
    "    ax2.set_title('Warped Image', fontsize=40)\n",
    "    path = 'output_images/'+folder[i]+'/Warped.jpg'\n",
    "    plt.savefig(path)\n",
    "    \n",
    "    # Save binary warped image\n",
    "    combined = combined.astype(np.uint8)*255\n",
    "    path = 'output_images/'+folder[i]+'/combined.jpg'\n",
    "    cv2.imwrite(path, combined)\n",
    "    \n",
    "    # Create figure to save color_fit_line.jpg\n",
    "    f, ax1 = plt.subplots(1,1)\n",
    "    f.tight_layout()\n",
    "    path = 'output_images/'+folder[i]+'/color_fit_line.jpg'\n",
    "    ax1.imshow(out_img)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.savefig(path)\n",
    "    \n",
    "    # Saving output image\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
    "    path = 'output_images/'+folder[i]+'/output.jpg'\n",
    "    cv2.imwrite(path, result)\n",
    "    \n",
    "    # Incrementing counter\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Define Line class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Line():\n",
    "\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = []\n",
    "        # average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None\n",
    "        # polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None\n",
    "        # polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]\n",
    "        # radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None\n",
    "        # distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None\n",
    "        # difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0, 0, 0], dtype='float')\n",
    "        # x values for detected line pixels\n",
    "        self.allx = None\n",
    "        # y values for detected line pixels\n",
    "        self.ally = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create objects Left and Right for left and right line repectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create object for left lane line\n",
    "Left = Line()\n",
    "# Create object for right lane line\n",
    "Right = Line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find new lines using last lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_new_fits(binary_warped, prev_left_fit, prev_right_fit):\n",
    "    # Define window margin\n",
    "    margin = 100\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Do not do a blind search but use the previous fits to locate the pixels\n",
    "    left_lane_inds = ((nonzerox > (prev_left_fit[0] * (nonzeroy**2) + prev_left_fit[1] * nonzeroy + prev_left_fit[2] - margin)) & (\n",
    "            nonzerox < (prev_left_fit[0] * (nonzeroy**2) + prev_left_fit[1] * nonzeroy + prev_left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (prev_right_fit[0] * (nonzeroy**2) + prev_right_fit[1] * nonzeroy + prev_right_fit[2] - margin)) & (\n",
    "            nonzerox < (prev_right_fit[0] * (nonzeroy**2) + prev_right_fit[1] * nonzeroy + prev_right_fit[2] + margin)))\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # Return None if line is not found \n",
    "    if (len(leftx) == 0) or (len(rightx) == 0):\n",
    "        return None, None\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Return left_fit and right_fit\n",
    "    return left_fit, right_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline to process frames of video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_frames(img):\n",
    "    \n",
    "    # Define averaging factor alpha\n",
    "    alpha = 0.8\n",
    "\n",
    "    # Get warped and undistorted image\n",
    "    binary_warped, dest = get_warped_images(img)\n",
    "\n",
    "    # Fit left and right lines\n",
    "    if (Left.detected == False) or (Right.detected == False):\n",
    "        Left.current_fit, Right.current_fit = get_fits(binary_warped)\n",
    "    else:\n",
    "        Left.current_fit, Right.current_fit = get_new_fits(binary_warped, Left.best_fit, Right.best_fit)\n",
    "\n",
    "    # Get y co-ordinates using np.linspace()\n",
    "    yvals = np.linspace(0, binary_warped.shape[0] - 1, binary_warped.shape[0])\n",
    "\n",
    "    # Find current_fit and best_fit for left lane line\n",
    "    if Left.current_fit != None:\n",
    "        # Define Left.best_fit, if it's None\n",
    "        if Left.best_fit == None:\n",
    "            Left.best_fit = Left.current_fit\n",
    "        \n",
    "        # Find x co-ordinates belonging to current fit using Left.current_fit and Left.best_fit respectively \n",
    "        current_leftx = Left.current_fit[0] * yvals**2 + Left.current_fit[1] * yvals + Left.current_fit[2]\n",
    "        last_leftx = Left.best_fit[0] * yvals**2 + Left.best_fit[1] * yvals + Left.best_fit[2]\n",
    "            \n",
    "        # Calculate new x using x co-ordinates calculated above\n",
    "        leftx = (alpha*last_leftx) + (1 - alpha)*current_leftx\n",
    "        \n",
    "        # Get new co-efficients corresponding to x co-ordinated calculated n last line\n",
    "        Left.best_fit = np.polyfit(yvals, leftx, 2)\n",
    "        \n",
    "        # Set flag Left.detected to True\n",
    "        Left.detected = True\n",
    "    else:\n",
    "        # Set flag Left.detected to False, if Left lane line not found\n",
    "        Left.detected = False\n",
    "        # Calculte current x co-ordinates using Left.best_fit\n",
    "        current_leftx = Left.best_fit[0] * yvals**2 + Left.best_fit[1] * yvals + Left.best_fit[2]\n",
    "\n",
    "    # Find current_fit and best_fit for right lane line\n",
    "    if Right.current_fit != None:\n",
    "        # Define Right.best_fit, if it's None\n",
    "        if Right.best_fit == None:\n",
    "            Right.best_fit = Right.current_fit\n",
    "            \n",
    "        # Find x co-ordinates belonging to current fit using Right.current_fit and Right.best_fit respectively \n",
    "        current_rightx = Right.current_fit[0] * yvals**2 + Right.current_fit[1] * yvals + Right.current_fit[2]\n",
    "        last_rightx = Right.best_fit[0] * yvals**2 + Right.best_fit[1] * yvals + Right.best_fit[2]\n",
    "            \n",
    "        # Calculate new x using x co-ordinates calculated above\n",
    "        rightx = (alpha*last_rightx) + (1 - alpha)*current_rightx\n",
    "        \n",
    "        # Get new co-efficients corresponding to x co-ordinated calculated n last line\n",
    "        Right.best_fit = np.polyfit(yvals, rightx, 2)\n",
    "        \n",
    "        # Set flag Left.detected to True\n",
    "        Right.detected = True\n",
    "    else:\n",
    "        # Set flag Left.detected to False, if Right lane line not found\n",
    "        Right.detected = False\n",
    "        # Calculte current x co-ordinates using Right.best_fit\n",
    "        current_rightx = Right.best_fit[0] * yvals**2 + Right.best_fit[1] * yvals + Right.best_fit[2]\n",
    "    \n",
    "    # Get Radius of curvature\n",
    "    Left.radius_of_curvature, Right.radius_of_curvature = get_radius_of_curvature(yvals, Left.best_fit, Right.best_fit)\n",
    "    \n",
    "    # Get Warped Back Image\n",
    "    warped_back = get_warped_back(dest, current_leftx, current_rightx, yvals)\n",
    "    \n",
    "    # Get position of vehicle w.r.t center \n",
    "    offset_from_center = get_offset_from_center(binary_warped, Left.best_fit, Right.best_fit)\n",
    "    \n",
    "    # Get output image\n",
    "    result = get_final_result(warped_back, int((Left.radius_of_curvature + Right.radius_of_curvature) / 2), offset_from_center)\n",
    "    \n",
    "    # Return result image\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process project video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_images/test-output.mp4\n",
      "[MoviePy] Writing video output_images/test-output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████▉  | 38/39 [00:36<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_images/test-output.mp4 \n",
      "\n",
      "Wall time: 55.9 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'output_images/test-output.mp4'\n",
    "clip1 = VideoFileClip(\"test_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_frames) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_images/P1-challenge-output.mp4\n",
      "[MoviePy] Writing video output_images/P1-challenge-output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 251/251 [03:39<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_images/P1-challenge-output.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "white_output = 'output_images/P1-challenge-output.mp4'\n",
    "clip1 = VideoFileClip(\"P1-challenge.mp4\")\n",
    "white_clip = clip1.fl_image(process_frames) #NOTE: this function expects color images!!\n",
    "white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_images/project-output.mp4\n",
      "[MoviePy] Writing video output_images/project-output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [17:09<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_images/project-output.mp4 \n",
      "\n",
      "Wall time: 17min 17s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'output_images/project-output.mp4'\n",
    "clip2 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip2.fl_image(process_frames) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Functions defined to experiment with detection of lane line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'test_images/test1.jpg'\n",
    "img = cv2.imread(path)\n",
    "hls = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "lower_yellow = np.array([20,100,100])\n",
    "upper_yellow = np.array([30,255,255])\n",
    "mask1 = cv2.inRange(hls, lower_yellow, upper_yellow)\n",
    "\n",
    "mask0 = cv2.inRange(hls, np.array([0,0,240]), np.array([255,15,255]))\n",
    "\n",
    "combined1 = mask1+mask0\n",
    "\n",
    "mask = np.zeros_like(combined1)\n",
    "ignore_mask_color = 255\n",
    "vertices = np.array([[(500, 450),(800, 450), (1100, 700), (100,700)]], dtype=np.int32)\n",
    "cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "combined1 = cv2.bitwise_and(combined1, mask)\n",
    "\n",
    "cv2.imwrite('testing.jpg',combined1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'test_images/test5.jpg'\n",
    "img = cv2.imread(path)\n",
    "binary_warped, warped, dest, combined = get_better_warped(img, caller = True)\n",
    "cv2.imwrite('testing1.jpg',combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_better_warped(image, caller = False):\n",
    "    \n",
    "    dest = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    img = np.copy(dest)\n",
    "    \n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    lower_yellow = np.array([20,100,100])\n",
    "    upper_yellow = np.array([30,255,255])\n",
    "    mask1 = cv2.inRange(hls, lower_yellow, upper_yellow)\n",
    "\n",
    "    mask0 = cv2.inRange(hls, np.array([255,255,255]), np.array([255,255,255]))\n",
    "\n",
    "    combined1 = mask1+mask0\n",
    "\n",
    "    mask = np.zeros_like(combined1)\n",
    "    ignore_mask_color = 255\n",
    "    vertices = np.array([[(500, 450),(800, 450), (1100, 700), (100,700)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    combined = cv2.bitwise_and(mask, combined1)\n",
    "    combined = combined.astype(np.uint8)\n",
    "    final = np.zeros_like(combined)\n",
    "    final[(combined == 255)] = 1\n",
    "    #combined = combined // 255\n",
    "    combined = final\n",
    "    combined_size = combined.shape[::-1]\n",
    "    \n",
    "    binary_warped = cv2.warpPerspective(combined, M, combined_size, flags = cv2.INTER_LINEAR)\n",
    "    warped = cv2.warpPerspective(image, M, combined_size, flags = cv2.INTER_LINEAR)\n",
    "    binary_warped = binary_warped.astype(np.uint8)\n",
    "    \n",
    "    if caller:\n",
    "        return binary_warped, warped, dest, combined\n",
    "    else:\n",
    "        return binary_warped, dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    # Define a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    # Define a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 255, 255], thickness=10):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    xtl, xtr, xbl, xbr = [], [], [], []\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if abs(y1 - y2) > 20 and x1 != x2:\n",
    "                slope = (y2 - y1) / (x2 - x1)\n",
    "                b = y2 - (slope * x2)\n",
    "                y = img.shape[0]\n",
    "                x = int((y - b) / slope)\n",
    "                x_ = int((325 - b) / slope)\n",
    "                if slope < 0:\n",
    "                    xbl.append(x)\n",
    "                    xtl.append(x_)\n",
    "                else:\n",
    "                    xbr.append(x)\n",
    "                    xtr.append(x_)\n",
    "    xtlmean = int(np.mean(xtl))\n",
    "    xblmean = int(np.mean(xbl))\n",
    "    xtrmean = int(np.mean(xtr))\n",
    "    xbrmean = int(np.mean(xbr))\n",
    "    yb = img.shape[0]\n",
    "    cv2.line(img, (xtlmean,600), (xblmean,720), color, thickness)\n",
    "    cv2.line(img, (xtrmean,600), (xbrmean,720), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
