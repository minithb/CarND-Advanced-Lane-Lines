{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "i = 0\n",
    "draw_img = None\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    draw_img = np.copy(img)\n",
    "\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(draw_img, (9,6), corners, ret)\n",
    "        \n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (draw_img.shape[0], draw_img.shape[1]), None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Undistort Chessboard Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "images = ['../camera_cal/calibration1.jpg','../camera_cal/calibration2.jpg','../camera_cal/calibration3.jpg',\n",
    "          '../camera_cal/calibration4.jpg','../camera_cal/calibration5.jpg']\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    draw_img = np.copy(img)\n",
    "    i += 1\n",
    "    \n",
    "    # Use cv2.calibrateCamera and cv2.undistort()\n",
    "    dest = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    # Defining path to save the figure\n",
    "    path = '../output_images/Undistorted_Images/Undistortion'+str(i)+'.jpg'\n",
    "    \n",
    "    # Defining figure\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    f.tight_layout()\n",
    "    \n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=25)\n",
    "    \n",
    "    ax2.imshow(dest)\n",
    "    ax2.set_title('Undistorted Image', fontsize=25)\n",
    "    \n",
    "    plt.savefig(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate tranformation matrix and calibration matix using Image & Object points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (720, 1280), None, None)\n",
    "src = np.float32([[585, 460], [203, 720], [1127, 720], [695, 460]])\n",
    "dst = np.float32([[320, 0], [320, 720], [960, 720], [960, 0]])\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "Minv = cv2.getPerspectiveTransform(dst, src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find binary warped image using color conversion, gradient etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_warped_images(image, s_thresh=(100, 255), sx_thresh=(100, 255), caller = False):\n",
    "    #ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (image.shape[0], image.shape[1]), None, None)\n",
    "    \n",
    "    #Use cv2.undistort() to undistort\n",
    "    dest = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    img = np.copy(dest)\n",
    "    \n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    combined = np.zeros_like(s_binary)\n",
    "    final = np.zeros_like(s_binary)\n",
    "    \n",
    "    combined[(sxbinary == 1) | (s_binary == 1)] = 1\n",
    "    combined_size = combined.shape[::-1]\n",
    "    \n",
    "    '''combined = combined.astype(np.uint8)\n",
    "    final = combined\n",
    "    #color_binary = np.dstack(( np.zeros_like(s_binary), sxbinary, s_binary))\n",
    "    \n",
    "    mask = np.zeros_like(combined)\n",
    "    ignore_mask_color = 255\n",
    "    \n",
    "    # This time we are defining a four sided polygon to mask\n",
    "    vertices = np.array([[(800, 450), (1150, 680), (150, 680), (500, 450)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    combined1 = cv2.bitwise_and(combined, mask)\n",
    "    \n",
    "    #vertices = np.array([[(580, 450), (770, 450), (1150, 680), (350, 680)]], dtype=np.int32)\n",
    "    #masked_edges = region_of_interest(combined, vertices)\n",
    "    line_image = hough_lines(combined1, 2, np.pi/180, 40, 60, 100)\n",
    "    line_image = line_image[:,:,0]\n",
    "    result = weighted_img(line_image, combined)\n",
    "    \n",
    "    combined = result // 255'''\n",
    "    \n",
    "    mask = np.zeros_like(combined)\n",
    "    ignore_mask_color = 1\n",
    "    \n",
    "    # This time we are defining a four sided polygon to mask\n",
    "    vertices = np.array([[(580, 460), (630, 460), (350, 680), (150, 680)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    combined1 = cv2.bitwise_and(combined, mask)\n",
    "\n",
    "    vertices = np.array([[(680,460),(750, 460), (1100, 680), (900,680)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    combined2 = cv2.bitwise_and(combined, mask)\n",
    "    \n",
    "    final[(combined1 == 1) | (combined2 == 1)] = 1\n",
    "    combined = final\n",
    "    \n",
    "    '''final = (final*255).astype(np.uint8)\n",
    "    line_image = hough_lines(final, 2, np.pi/180, 40, 60, 100)\n",
    "    line_image = line_image[:,:,0]\n",
    "    result = weighted_img(line_image, (combined*255).astype(np.uint8))\n",
    "    #line_image = line_image[:,:,0] // 255\n",
    "    combined = result // 255'''\n",
    "    \n",
    "    binary_warped = cv2.warpPerspective(combined, M, combined_size, flags = cv2.INTER_LINEAR)\n",
    "    warped = cv2.warpPerspective(image, M, combined_size, flags = cv2.INTER_LINEAR)\n",
    "    binary_warped = binary_warped.astype(np.uint8)\n",
    "    \n",
    "    if caller:\n",
    "        return binary_warped, warped, dest, combined\n",
    "    else:\n",
    "        return binary_warped, dest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## Finding midpoint and peaks of left and right line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_values(binary_warped):\n",
    "    histogram = np.sum(binary_warped[int(binary_warped.shape[0]/2):,:], axis=0)\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    return midpoint, leftx_base, rightx_base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding to get polynimial fit of left lane and right lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_fits(binary_warped, caller = False):\n",
    "    \n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint, leftx_base, rightx_base = get_values(binary_warped)\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(out_img.shape[0]/nwindows)\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = int(out_img.shape[0]) - (window+1)*window_height\n",
    "        win_y_high = int(out_img.shape[0]) - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        #cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        #cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    if caller:\n",
    "        return left_fit, right_fit, out_img\n",
    "    else:\n",
    "        return left_fit, right_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Calculate Radius of Curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_radius_of_curvature(ploty, left_fit, right_fit):\n",
    "    y_eval = np.max(ploty)\n",
    "    #left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    #right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    #print(left_curverad, right_curverad)\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    left_fitx = left_fit[0] * ploty**2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty**2 + right_fit[1] * ploty + right_fit[2]\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty * ym_per_pix, left_fitx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty * ym_per_pix, right_fitx * xm_per_pix, 2)\n",
    "\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "\n",
    "    left_fitx = left_fit[0] * ploty**2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty**2 + right_fit[1] * ploty + right_fit[2]\n",
    "    y_eval = np.max(ploty)\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty * ym_per_pix, left_fitx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty * ym_per_pix, right_fitx * xm_per_pix, 2)\n",
    "\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[\n",
    "                     1])**2)**1.5) / np.absolute(2 * left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2 * right_fit_cr[0] * y_eval * ym_per_pix + right_fit_cr[\n",
    "                      1])**2)**1.5) / np.absolute(2 * right_fit_cr[0])\n",
    "\n",
    "    # Now our radius of curvature is in meters\n",
    "    #print(left_curverad, 'm', right_curverad, 'm')\n",
    "    # Example values: 632.1 m    626.2 m\n",
    "    \n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Offset from center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_offset_from_center(binary_warped, left_fit, right_fit):\n",
    "    y = binary_warped.shape[0]\n",
    "    left_lane_pixel = left_fit[0] * y**2 + left_fit[1] * y + left_fit[2]\n",
    "    right_lane_pixel = right_fit[0] * y**2 + right_fit[1] * y + right_fit[2]\n",
    "    \n",
    "    xm_per_pix = 3.7 / 700  # meteres per pixel in x dimension\n",
    "    screen_middle_pixel = binary_warped.shape[1] / 2\n",
    "    car_middle_pixel = int((right_lane_pixel + left_lane_pixel) / 2)\n",
    "    pixels_off_center = screen_middle_pixel - car_middle_pixel\n",
    "    offset_from_center = xm_per_pix * pixels_off_center\n",
    "    \n",
    "    return offset_from_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get warped back image using Inverse Perspective Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_warped_back(warped, dest, left_fitx, right_fitx, ploty, Minv):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 255))\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (warped.shape[1], warped.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    warped_back = cv2.addWeighted(dest, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    return warped_back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_final_result(result, avg_radius, offset_from_center):\n",
    "    # Print radius of curvature on video\n",
    "    cv2.putText(result, 'Radius of Curvature {}(m)'.format(avg_radius), (120, 140),\n",
    "                fontFace=15, fontScale=2, color=(255, 255, 0), thickness=2)\n",
    "    \n",
    "    if offset_from_center < 0:\n",
    "        # Print distance from center on video\n",
    "        cv2.putText(result, 'Vehicle is {:.2f}m left of center'.format(abs(offset_from_center)), (100, 80),\n",
    "                        fontFace=15, fontScale=2, color=(255, 255, 0), thickness=2)\n",
    "    else:\n",
    "        cv2.putText(result, 'Vehicle is {:.2f}m right of center'.format(offset_from_center), (100, 80),\n",
    "                        fontFace=15, fontScale=2, color=(255, 255, 0), thickness=2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline to test on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "raw_images = glob.glob('../test_images/*.jpg')\n",
    "#raw_images = raw_images[5:7]\n",
    "for fname in raw_images:\n",
    "    image = mpimg.imread(fname)\n",
    "    out_img=None\n",
    "    result=None\n",
    "    \n",
    "    #binary_warped, warped, dest, combined = get_better_warped(image, caller = True)\n",
    "    binary_warped, warped, dest, combined = get_warped_images(image, caller = True)    \n",
    "    \n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    left_fit, right_fit, out_img = get_fits(binary_warped, caller = True)\n",
    "    \n",
    "    ploty = np.linspace(0, int(binary_warped.shape[0])-1, int(binary_warped.shape[0]))\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    #plt.imshow(out_img)\n",
    "    #plt.xlim(0, 1280)\n",
    "    #plt.ylim(720, 0)\n",
    "    \n",
    "    #ax5.plot(left_fitx, ploty, color='yellow')\n",
    "    #ax5.plot(right_fitx, ploty, color='yellow')\n",
    "    #ax5.xlim(0, 1280)\n",
    "    #ax5.ylim(720, 0)\n",
    "    \n",
    "    left_curverad, right_curverad = get_radius_of_curvature(ploty, left_fit, right_fit)\n",
    "    \n",
    "    # print(left_curverad, 'm', right_curverad, 'm')\n",
    "    # Example values: 632.1 m    626.2 m\n",
    "    \n",
    "    warped_back = get_warped_back(binary_warped, dest, left_fitx, right_fitx, ploty, Minv)\n",
    "    \n",
    "    offset_from_center = get_offset_from_center(binary_warped, left_fit, right_fit)\n",
    "    \n",
    "    result = image\n",
    "    result = get_final_result(warped_back, int((left_curverad + right_curverad) / 2), offset_from_center)\n",
    "    \n",
    "    folder = ['straight_lines1', 'straight_lines2', 'test1', 'test2', 'test3', 'test4', 'test5', 'test6']\n",
    "    \n",
    "    #plt.imshow(result)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    f.tight_layout()\n",
    "    \n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=40)\n",
    "\n",
    "    ax2.imshow(dest)\n",
    "    ax2.set_title('Undistorted Image', fontsize=40)\n",
    "    path = '../output_images/'+folder[i]+'/Undistort.jpg'\n",
    "    #plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.savefig(path)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    f.tight_layout()\n",
    "    \n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=40)\n",
    "\n",
    "    ax2.imshow(warped)\n",
    "    ax2.set_title('Warped Image', fontsize=40)\n",
    "    path = '../output_images/'+folder[i]+'/Warped.jpg'\n",
    "    #plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.savefig(path)\n",
    "    \n",
    "    combined = combined.astype(np.uint8)*255\n",
    "    path = '../output_images/'+folder[i]+'/combined.jpg'\n",
    "    cv2.imwrite(path, combined)\n",
    "    \n",
    "    out_img = cv2.cvtColor(out_img, cv2.COLOR_RGB2BGR)\n",
    "    path = '../output_images/'+folder[i]+'/color_fit_line.jpg'\n",
    "    cv2.imwrite(path, out_img)\n",
    "    \n",
    "    result = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
    "    path = '../output_images/'+folder[i]+'/output.jpg'\n",
    "    cv2.imwrite(path, result)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Defining Line class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Line():\n",
    "\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = []\n",
    "        # average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None\n",
    "        # polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None\n",
    "        # polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]\n",
    "        # radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None\n",
    "        # distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None\n",
    "        # difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0, 0, 0], dtype='float')\n",
    "        # x values for detected line pixels\n",
    "        self.allx = None\n",
    "        # y values for detected line pixels\n",
    "        self.ally = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating objects Left and Right for left and right line repectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Left = Line()\n",
    "Right = Line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find new lines using last lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_new_fits(binary_warped, prev_left_fit, prev_right_fit):\n",
    "    margin = 100\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Do not do a blind search but use the previous fits to locate the pixels\n",
    "    left_lane_inds = ((nonzerox > (prev_left_fit[0] * (nonzeroy**2) + prev_left_fit[1] * nonzeroy + prev_left_fit[2] - margin)) & (\n",
    "            nonzerox < (prev_left_fit[0] * (nonzeroy**2) + prev_left_fit[1] * nonzeroy + prev_left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (prev_right_fit[0] * (nonzeroy**2) + prev_right_fit[1] * nonzeroy + prev_right_fit[2] - margin)) & (\n",
    "            nonzerox < (prev_right_fit[0] * (nonzeroy**2) + prev_right_fit[1] * nonzeroy + prev_right_fit[2] + margin)))\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    if (len(leftx) == 0) or (len(rightx) == 0):\n",
    "        return None, None\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    return left_fit, right_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline to process frames of video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    \n",
    "    alpha = 0.8\n",
    "\n",
    "    # Pre-process the image to get an undistored, thresholded, binary, perspective\n",
    "    # transformed image\n",
    "    binary_warped, dest = get_warped_images(img)\n",
    "\n",
    "    # Fit left and right lines\n",
    "    if (Left.detected == False) or (Right.detected == False):\n",
    "        Left.current_fit, Right.current_fit = get_fits(binary_warped)\n",
    "    else:\n",
    "        Left.current_fit, Right.current_fit = get_new_fits(binary_warped, Left.best_fit, Right.best_fit)\n",
    "\n",
    "    # Smooth and process lines\n",
    "    \n",
    "    yvals = np.linspace(0, binary_warped.shape[0] - 1, binary_warped.shape[0])\n",
    "\n",
    "    # Process left line\n",
    "    if Left.current_fit != None:\n",
    "    \n",
    "        if Left.best_fit == None:\n",
    "            Left.best_fit = Left.current_fit\n",
    "        \n",
    "        # Smooth the xvals over previous fit and current-fit\n",
    "        current_leftx = Left.current_fit[0] * yvals**2 + Left.current_fit[1] * yvals + Left.current_fit[2]\n",
    "        last_leftx = Left.best_fit[0] * yvals**2 + Left.best_fit[1] * yvals + Left.best_fit[2] \n",
    "            \n",
    "        # Update the x based on the moving average\n",
    "        leftx = (alpha*last_leftx) + (1 - alpha)*current_leftx\n",
    "        \n",
    "        # Recompute the best fit coefficients\n",
    "        Left.best_fit = np.polyfit(yvals, leftx, 2)\n",
    "        \n",
    "        # Found left lane\n",
    "        Left.detected = True\n",
    "    else:\n",
    "        Left.detected = False\n",
    "        current_leftx = Left.best_fit[0] * yvals**2 + Left.best_fit[1] * yvals + Left.best_fit[2]\n",
    "\n",
    "    # Process right line\n",
    "    if Right.current_fit != None:\n",
    "        \n",
    "        if Right.best_fit == None:\n",
    "            Right.best_fit = Right.current_fit\n",
    "            \n",
    "        # Smooth the xvals over previous fit and current-fit   \n",
    "        current_rightx = Right.current_fit[0] * yvals**2 + Right.current_fit[1] * yvals + Right.current_fit[2]\n",
    "        last_rightx = Right.best_fit[0] * yvals**2 + Right.best_fit[1] * yvals + Right.best_fit[2]\n",
    "            \n",
    "        # Update the x based on the moving average\n",
    "        rightx = (alpha*last_rightx) + (1 - alpha)*current_rightx\n",
    "        \n",
    "        # Recompute the best fit coefficients\n",
    "        Right.best_fit = np.polyfit(yvals, rightx, 2)\n",
    "        \n",
    "        # Found Right line\n",
    "        Right.detected = True\n",
    "    else:\n",
    "        Right.detected = False\n",
    "        current_rightx = Right.best_fit[0] * yvals**2 + Right.best_fit[1] * yvals + Right.best_fit[2]\n",
    "        \n",
    "    Left.radius_of_curvature, Right.radius_of_curvature = get_radius_of_curvature(yvals, Left.best_fit, Right.best_fit)\n",
    "    \n",
    "    #print(left_curverad, 'm', right_curverad, 'm')\n",
    "    # Example values: 632.1 m    626.2 m\n",
    "    \n",
    "    # Get Warped Back Image\n",
    "    warped_back = get_warped_back(binary_warped, dest, current_leftx, current_rightx, yvals, Minv)\n",
    "    \n",
    "    offset_from_center = get_offset_from_center(binary_warped, Left.best_fit, Right.best_fit)\n",
    "\n",
    "    result = get_final_result(warped_back, int((Left.radius_of_curvature + Right.radius_of_curvature) / 2), offset_from_center)\n",
    "    \n",
    "    # Return result image\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process project video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test-output.mp4\n",
      "[MoviePy] Writing video test-output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████▉  | 38/39 [00:27<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test-output.mp4 \n",
      "\n",
      "Wall time: 33.5 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'test-output.mp4'\n",
    "clip2 = VideoFileClip(\"../test_video.mp4\")\n",
    "white_clip = clip2.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ../project-output.mp4\n",
      "[MoviePy] Writing video ../project-output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [08:29<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ../project-output.mp4 \n",
      "\n",
      "Wall time: 8min 33s\n"
     ]
    }
   ],
   "source": [
    "white_output = '../project-output.mp4'\n",
    "clip2 = VideoFileClip(\"../project_video.mp4\")\n",
    "white_clip = clip2.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ../challenge-output.mp4\n",
      "[MoviePy] Writing video ../challenge-output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 251/251 [01:46<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ../challenge-output.mp4 \n",
      "\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "white_output = '../challenge-output.mp4'\n",
    "clip1 = VideoFileClip(\"../challenge.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "path = '../test_images/test1.jpg'\n",
    "img = cv2.imread(path)\n",
    "hls = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "lower_yellow = np.array([20,100,100])\n",
    "upper_yellow = np.array([30,255,255])\n",
    "mask1 = cv2.inRange(hls, lower_yellow, upper_yellow)\n",
    "\n",
    "mask0 = cv2.inRange(hls, np.array([0,0,240]), np.array([255,15,255]))\n",
    "\n",
    "combined1 = mask1+mask0\n",
    "\n",
    "mask = np.zeros_like(combined1)\n",
    "ignore_mask_color = 255\n",
    "vertices = np.array([[(500, 450),(800, 450), (1100, 700), (100,700)]], dtype=np.int32)\n",
    "cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "combined1 = cv2.bitwise_and(combined1, mask)\n",
    "\n",
    "cv2.imwrite('testing.jpg',combined1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "path = '../test_images/test5.jpg'\n",
    "img = cv2.imread(path)\n",
    "binary_warped, warped, dest, combined = get_better_warped(img, caller = True)\n",
    "cv2.imwrite('testing.jpg',combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_better_warped(image, caller = False):\n",
    "    \n",
    "    dest = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    img = np.copy(dest)\n",
    "    \n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    lower_yellow = np.array([20,100,100])\n",
    "    upper_yellow = np.array([30,255,255])\n",
    "    mask1 = cv2.inRange(hls, lower_yellow, upper_yellow)\n",
    "\n",
    "    mask0 = cv2.inRange(hls, np.array([255,255,255]), np.array([255,255,255]))\n",
    "\n",
    "    combined1 = mask1+mask0\n",
    "\n",
    "    mask = np.zeros_like(combined1)\n",
    "    ignore_mask_color = 255\n",
    "    vertices = np.array([[(500, 450),(800, 450), (1100, 700), (100,700)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    combined = cv2.bitwise_and(mask, combined1)\n",
    "    combined = combined.astype(np.uint8)\n",
    "    final = np.zeros_like(combined)\n",
    "    final[(combined == 255)] = 1\n",
    "    #combined = combined // 255\n",
    "    combined = final\n",
    "    combined_size = combined.shape[::-1]\n",
    "    \n",
    "    binary_warped = cv2.warpPerspective(combined, M, combined_size, flags = cv2.INTER_LINEAR)\n",
    "    warped = cv2.warpPerspective(image, M, combined_size, flags = cv2.INTER_LINEAR)\n",
    "    binary_warped = binary_warped.astype(np.uint8)\n",
    "    \n",
    "    if caller:\n",
    "        return binary_warped, warped, dest, combined\n",
    "    else:\n",
    "        return binary_warped, dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 255, 255], thickness=10):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    xtl, xtr, xbl, xbr = [], [], [], []\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if abs(y1 - y2) > 20 and x1 != x2:\n",
    "                slope = (y2 - y1) / (x2 - x1)\n",
    "                b = y2 - (slope * x2)\n",
    "                y = img.shape[0]\n",
    "                x = int((y - b) / slope)\n",
    "                x_ = int((325 - b) / slope)\n",
    "                if slope < 0:\n",
    "                    xbl.append(x)\n",
    "                    xtl.append(x_)\n",
    "                else:\n",
    "                    xbr.append(x)\n",
    "                    xtr.append(x_)\n",
    "    xtlmean = int(np.mean(xtl))\n",
    "    xblmean = int(np.mean(xbl))\n",
    "    xtrmean = int(np.mean(xtr))\n",
    "    xbrmean = int(np.mean(xbr))\n",
    "    yb = img.shape[0]\n",
    "    cv2.line(img, (xtlmean,600), (xblmean,720), color, thickness)\n",
    "    cv2.line(img, (xtrmean,600), (xbrmean,720), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
